# üéØ Voice Chat Best Practices & Performance Guide

## üìä Performance Optimization

### 1. **Memory Management**

```typescript
// ‚úÖ GOOD: Clean up speech recognition on unmount
useEffect(() => {
  const recognition = new SpeechRecognition();
  // ... setup ...
  
  return () => {
    if (recognition) {
      recognition.abort();
      recognition = null;
    }
  };
}, []);

// ‚úÖ GOOD: Cancel speech synthesis when component unmounts
useEffect(() => {
  return () => {
    if (window.speechSynthesis) {
      window.speechSynthesis.cancel();
    }
  };
}, []);

// ‚ùå BAD: Memory leaks from not cleaning up
const recognition = new SpeechRecognition();
recognition.start(); // Never stopped or cleaned up
```

### 2. **Debouncing & Throttling**

```typescript
// ‚úÖ GOOD: Debounce transcript updates
import { useMemo } from 'react';
import debounce from 'lodash/debounce';

const debouncedSetInput = useMemo(
  () => debounce((text: string) => setInput(text), 300),
  []
);

useEffect(() => {
  if (interimTranscript) {
    debouncedSetInput(interimTranscript);
  }
}, [interimTranscript, debouncedSetInput]);

// ‚ùå BAD: Update on every keystroke/interim result
useEffect(() => {
  setInput(interimTranscript); // Too frequent updates
}, [interimTranscript]);
```

### 3. **Lazy Loading**

```typescript
// ‚úÖ GOOD: Lazy load voice components
import { lazy, Suspense } from 'react';

const VoiceGeminiChatWindow = lazy(() => 
  import('@/components/messages/VoiceGeminiChatWindow')
);

export const MessagesPage = () => (
  <Suspense fallback={<ChatLoadingSkeleton />}>
    <VoiceGeminiChatWindow />
  </Suspense>
);

// ‚ùå BAD: Import everything upfront
import { VoiceGeminiChatWindow } from '@/components/messages/VoiceGeminiChatWindow';
// Increases initial bundle size
```

### 4. **Prevent Re-renders**

```typescript
// ‚úÖ GOOD: Memoize callbacks
const handleVoiceClick = useCallback(() => {
  if (isListening) {
    stopListening();
  } else {
    startListening();
  }
}, [isListening, stopListening, startListening]);

// ‚úÖ GOOD: Memoize expensive computations
const processedMessages = useMemo(() => {
  return messages.map(msg => ({
    ...msg,
    formatted: formatMessage(msg.content),
  }));
}, [messages]);

// ‚ùå BAD: Inline functions cause re-renders
<Button onClick={() => handleClick()}>Click</Button>
```

---

## üîí Security Best Practices

### 1. **Input Validation**

```typescript
// ‚úÖ GOOD: Sanitize voice input before sending
const handleVoiceInput = async (text: string) => {
  // Remove potentially harmful characters
  const sanitized = text
    .trim()
    .replace(/[<>]/g, '') // Remove HTML tags
    .substring(0, 1000);   // Limit length
  
  if (sanitized.length < 2) {
    console.warn('Input too short');
    return;
  }
  
  await sendMessage(sanitized);
};

// ‚ùå BAD: Send raw input without validation
await sendMessage(text); // Could contain malicious content
```

### 2. **Rate Limiting**

```typescript
// ‚úÖ GOOD: Implement client-side rate limiting
const [lastRequestTime, setLastRequestTime] = useState(0);
const MIN_REQUEST_INTERVAL = 1000; // 1 second

const handleSend = async (text: string) => {
  const now = Date.now();
  if (now - lastRequestTime < MIN_REQUEST_INTERVAL) {
    console.warn('Too many requests');
    return;
  }
  
  setLastRequestTime(now);
  await sendMessage(text);
};

// ‚ùå BAD: Allow unlimited requests
await sendMessage(text); // Can be spammed
```

### 3. **Error Handling**

```typescript
// ‚úÖ GOOD: Comprehensive error handling
useSpeechToText({
  onError: (error) => {
    // Log error for debugging
    console.error('[Voice] Error:', error);
    
    // Show user-friendly message
    if (error.includes('not-allowed')) {
      showNotification('Please enable microphone access', 'error');
    } else if (error.includes('network')) {
      showNotification('Network error. Please check your connection', 'error');
    } else {
      showNotification('Voice input error. Please try typing', 'error');
    }
    
    // Fallback to text input
    setVoiceInputEnabled(false);
  },
});

// ‚ùå BAD: Ignore errors
useSpeechToText({
  onError: (error) => console.log(error), // User left confused
});
```

---

## üåê Browser Compatibility Handling

### 1. **Feature Detection**

```typescript
// ‚úÖ GOOD: Check feature support before rendering
const VoiceFeature = () => {
  const hasVoiceInput = 'SpeechRecognition' in window || 
                        'webkitSpeechRecognition' in window;
  const hasVoiceOutput = 'speechSynthesis' in window;
  
  if (!hasVoiceInput && !hasVoiceOutput) {
    return <TextOnlyChat />;
  }
  
  if (!hasVoiceInput) {
    return <ChatWithVoiceOutputOnly />;
  }
  
  return <FullVoiceChat />;
};

// ‚ùå BAD: Assume support exists
return <VoiceChat />; // May crash in unsupported browsers
```

### 2. **Progressive Enhancement**

```typescript
// ‚úÖ GOOD: Add voice as enhancement, not requirement
export const Chat = () => {
  const voiceSupported = useSpeechToText().isSupported;
  
  return (
    <Box>
      {/* Core functionality (always works) */}
      <TextInput onSend={sendMessage} />
      
      {/* Enhanced functionality (optional) */}
      {voiceSupported && (
        <VoiceInput onSend={sendMessage} />
      )}
    </Box>
  );
};

// ‚ùå BAD: Voice as requirement
if (!voiceSupported) {
  return <div>Voice not supported. Cannot use app.</div>;
}
```

### 3. **Polyfills & Fallbacks**

```typescript
// ‚úÖ GOOD: Provide graceful fallbacks
const SpeechRecognition = window.SpeechRecognition || 
                         window.webkitSpeechRecognition ||
                         null;

if (!SpeechRecognition) {
  console.warn('SpeechRecognition not available');
  // Show text-only UI
}

// ‚úÖ GOOD: Show clear browser recommendations
if (!voiceSupported) {
  return (
    <Alert status="info">
      <AlertIcon />
      For voice features, please use Chrome, Edge, or Safari.
      <Button onClick={() => window.open('https://google.com/chrome')}>
        Download Chrome
      </Button>
    </Alert>
  );
}
```

---

## üé® UX Best Practices

### 1. **Visual Feedback**

```typescript
// ‚úÖ GOOD: Clear visual states
{isListening && (
  <Box 
    p={3} 
    bg="red.50" 
    borderRadius="md"
    animation="pulse 2s infinite"
  >
    <HStack>
      <Box 
        w="10px" 
        h="10px" 
        borderRadius="full" 
        bg="red.500"
        animation="pulse 1s infinite"
      />
      <Text fontWeight="medium" color="red.700">
        Listening... Speak now
      </Text>
    </HStack>
  </Box>
)}

// ‚ùå BAD: No visual feedback
{isListening && <div>Recording</div>} // Easy to miss
```

### 2. **User Instructions**

```typescript
// ‚úÖ GOOD: Provide clear instructions
<VStack align="start">
  <Text fontSize="lg" fontWeight="bold">How to use voice:</Text>
  <OrderedList>
    <ListItem>Click the microphone button üé§</ListItem>
    <ListItem>Allow microphone access when prompted</ListItem>
    <ListItem>Speak your message clearly</ListItem>
    <ListItem>Click again to stop (or wait for auto-stop)</ListItem>
  </OrderedList>
  <Text fontSize="sm" color="gray.600">
    Tip: Reduce background noise for best results
  </Text>
</VStack>

// ‚ùå BAD: Assume users know what to do
<Button>üé§</Button> // No explanation
```

### 3. **Accessibility**

```typescript
// ‚úÖ GOOD: Full accessibility support
<IconButton
  icon={<FiMic />}
  aria-label="Start voice input"
  aria-pressed={isListening}
  aria-live="polite"
  aria-describedby="voice-help"
  onClick={handleVoiceClick}
/>
<Text id="voice-help" srOnly>
  Click to start voice recognition. Speak your message clearly.
</Text>

// ‚úÖ GOOD: Keyboard shortcuts
useEffect(() => {
  const handleKeyDown = (e: KeyboardEvent) => {
    if (e.ctrlKey && e.key === 'm') {
      e.preventDefault();
      handleVoiceClick();
    }
  };
  window.addEventListener('keydown', handleKeyDown);
  return () => window.removeEventListener('keydown', handleKeyDown);
}, [handleVoiceClick]);

// ‚ùå BAD: Mouse-only interaction
<div onClick={handleVoiceClick}>üé§</div> // Not keyboard accessible
```

---

## üì± Mobile Optimization

### 1. **Touch Targets**

```typescript
// ‚úÖ GOOD: Large touch targets (minimum 44x44px)
<IconButton
  size="lg"  // 44px
  icon={<FiMic />}
  onClick={handleVoiceClick}
/>

// ‚ùå BAD: Small touch targets
<IconButton size="xs" /> // Too small for mobile
```

### 2. **Mobile-Specific Features**

```typescript
// ‚úÖ GOOD: Detect mobile and adjust UX
const isMobile = /iPhone|iPad|iPod|Android/i.test(navigator.userAgent);

if (isMobile) {
  // On mobile, voice input is more natural
  // Show larger mic button, hide some text input features
}

// ‚úÖ GOOD: Handle mobile keyboard
useEffect(() => {
  if (isMobile && isListening) {
    // Hide keyboard when voice starts
    document.activeElement?.blur();
  }
}, [isListening, isMobile]);
```

### 3. **Network Awareness**

```typescript
// ‚úÖ GOOD: Warn on slow connection
const connection = (navigator as any).connection;
if (connection && connection.effectiveType === '2g') {
  showWarning('Voice features may be slow on your connection');
}

// ‚úÖ GOOD: Handle offline mode
useEffect(() => {
  const handleOffline = () => {
    if (isListening) {
      stopListening();
      showError('Voice input requires internet connection');
    }
  };
  
  window.addEventListener('offline', handleOffline);
  return () => window.removeEventListener('offline', handleOffline);
}, [isListening, stopListening]);
```

---

## üß™ Testing Strategies

### 1. **Unit Tests**

```typescript
import { renderHook, act } from '@testing-library/react-hooks';
import { useSpeechToText } from '@/hooks/useSpeechToText';

describe('useSpeechToText', () => {
  it('should start listening', () => {
    const { result } = renderHook(() => useSpeechToText());
    
    act(() => {
      result.current.startListening();
    });
    
    expect(result.current.isListening).toBe(true);
  });
  
  it('should handle transcripts', async () => {
    const onTranscript = jest.fn();
    const { result } = renderHook(() => 
      useSpeechToText({ onTranscript })
    );
    
    // Simulate speech recognition result
    // ... test logic ...
    
    expect(onTranscript).toHaveBeenCalledWith('test transcript');
  });
});
```

### 2. **Integration Tests**

```typescript
import { render, screen, fireEvent } from '@testing-library/react';
import { VoiceGeminiChatWindow } from './VoiceGeminiChatWindow';

describe('VoiceGeminiChatWindow', () => {
  it('should show microphone button when supported', () => {
    render(<VoiceGeminiChatWindow />);
    const micButton = screen.getByLabelText('Start voice input');
    expect(micButton).toBeInTheDocument();
  });
  
  it('should toggle listening state', () => {
    render(<VoiceGeminiChatWindow />);
    const micButton = screen.getByLabelText('Start voice input');
    
    fireEvent.click(micButton);
    expect(screen.getByText(/listening/i)).toBeInTheDocument();
    
    fireEvent.click(micButton);
    expect(screen.queryByText(/listening/i)).not.toBeInTheDocument();
  });
});
```

### 3. **Manual Testing Checklist**

```
Desktop (Chrome):
[ ] Microphone permission prompt appears
[ ] Voice input works correctly
[ ] Interim results display
[ ] Final transcript sent
[ ] Bot response spoken aloud
[ ] Multiple languages work
[ ] Error handling works

Desktop (Firefox):
[ ] Shows "not supported" warning
[ ] Text input still works
[ ] No errors in console

Mobile (Chrome/Safari):
[ ] Touch targets large enough
[ ] Keyboard hides when recording
[ ] Network warning on slow connection
[ ] Works in portrait/landscape

Edge Cases:
[ ] Works without internet (shows error)
[ ] Works with microphone unplugged (shows error)
[ ] Works with permission denied (shows instructions)
[ ] Handles long pauses during speech
[ ] Handles background noise
[ ] Handles multiple rapid clicks
```

---

## üéØ Performance Metrics

### Key Metrics to Monitor

```typescript
// ‚úÖ GOOD: Track performance
const trackVoicePerformance = () => {
  const metrics = {
    recognitionStartTime: 0,
    recognitionEndTime: 0,
    apiCallTime: 0,
    synthesisTime: 0,
  };
  
  // Start recognition
  metrics.recognitionStartTime = performance.now();
  startListening();
  
  // On transcript
  onTranscript: (text) => {
    metrics.recognitionEndTime = performance.now();
    console.log('Recognition took:', 
      metrics.recognitionEndTime - metrics.recognitionStartTime, 'ms'
    );
  }
  
  // API call
  const apiStart = performance.now();
  await sendMessage(text);
  metrics.apiCallTime = performance.now() - apiStart;
  
  // Synthesis
  const synthStart = performance.now();
  speak(response);
  // On end callback
  metrics.synthesisTime = performance.now() - synthStart;
  
  // Log to analytics
  analytics.track('voice_interaction', metrics);
};
```

### Target Performance

- Voice recognition start: < 100ms
- Interim result update: < 50ms
- Final transcript: < 500ms after speech ends
- API response: < 2000ms (depends on backend)
- Speech synthesis start: < 100ms
- Total interaction time: < 5 seconds

---

## üìä Analytics & Monitoring

### What to Track

```typescript
// Track voice feature usage
analytics.track('voice_input_started', {
  language: selectedLanguage,
  timestamp: Date.now(),
});

analytics.track('voice_input_completed', {
  transcript_length: transcript.length,
  duration_ms: duration,
  success: true,
});

analytics.track('voice_output_played', {
  message_length: message.length,
  auto_play: true,
});

analytics.track('voice_error', {
  error_type: error,
  browser: navigator.userAgent,
});

// Track feature adoption
analytics.track('voice_vs_text', {
  voice_interactions: voiceCount,
  text_interactions: textCount,
  ratio: voiceCount / (voiceCount + textCount),
});
```

### Monitoring Alerts

```typescript
// Set up alerts for:
- High error rate (> 10%)
- Low usage rate (< 5% of users trying voice)
- Performance degradation (> 1s latency)
- Browser incompatibility increases
- Permission denial rate (> 30%)
```

---

## üöÄ Optimization Checklist

### Performance
- [ ] Clean up event listeners on unmount
- [ ] Cancel speech synthesis on navigation
- [ ] Debounce interim transcript updates
- [ ] Memoize expensive computations
- [ ] Lazy load voice components
- [ ] Implement code splitting
- [ ] Use React.memo for message components

### Security
- [ ] Validate and sanitize all voice input
- [ ] Implement rate limiting
- [ ] Handle errors gracefully
- [ ] Log security events
- [ ] Don't store sensitive voice data

### UX
- [ ] Provide clear visual feedback
- [ ] Show helpful instructions
- [ ] Support keyboard shortcuts
- [ ] Implement accessibility features
- [ ] Handle edge cases gracefully
- [ ] Test on multiple devices

### Compatibility
- [ ] Feature detection before rendering
- [ ] Graceful degradation
- [ ] Browser-specific adjustments
- [ ] Mobile optimization
- [ ] Network awareness

### Testing
- [ ] Write unit tests for hooks
- [ ] Integration tests for components
- [ ] Manual testing on all browsers
- [ ] Mobile device testing
- [ ] Edge case testing

### Monitoring
- [ ] Track usage metrics
- [ ] Monitor error rates
- [ ] Measure performance
- [ ] Set up alerts
- [ ] Regular reviews

---

## üí° Quick Wins

1. **Add visual pulse animation** for recording indicator
2. **Show interim transcript** in real-time for better UX
3. **Auto-focus input** after voice stops
4. **Keyboard shortcut** (Ctrl+M) for quick access
5. **Language persistence** (save to localStorage)
6. **Voice preset prompts** for common queries
7. **Waveform visualization** during recording
8. **Success sound** after message sent
9. **Haptic feedback** on mobile devices
10. **Voice tutorial** on first use

---

## üéì Learning Resources

- [Web Speech API Tutorial](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API/Using_the_Web_Speech_API)
- [Speech Recognition Best Practices](https://web.dev/speech-recognition/)
- [Accessibility Guidelines](https://www.w3.org/WAI/WCAG21/quickref/)
- [React Performance Optimization](https://react.dev/learn/render-and-commit)
- [Mobile Web Best Practices](https://web.dev/mobile/)

---

**Remember:** Voice is an enhancement, not a requirement. Always provide text alternatives! üéØ
