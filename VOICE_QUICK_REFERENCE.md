# ğŸ¤ Voice Integration Quick Reference

## ğŸ“¦ Files Created

```
web-frontend/src/
â”œâ”€â”€ hooks/
â”‚   â”œâ”€â”€ useSpeechToText.ts          âœ… Voice input hook
â”‚   â””â”€â”€ useTextToSpeech.ts          âœ… Voice output hook
â””â”€â”€ components/messages/
    â”œâ”€â”€ VoiceGeminiChatWindow.tsx   âœ… Full-featured voice chat
    â””â”€â”€ SimpleVoiceChat.tsx         âœ… Minimal example

Documentation:
â”œâ”€â”€ VOICE_INTEGRATION_GUIDE.md      âœ… Complete guide
â”œâ”€â”€ VOICE_BEST_PRACTICES.md         âœ… Performance & best practices
â””â”€â”€ VOICE_INTEGRATION_EXAMPLE.tsx   âœ… Step-by-step example
```

---

## âš¡ Quick Start (3 Minutes)

### Method 1: Use Pre-Built Component

```typescript
// In your MessagesPage or wherever you want the chat
import { VoiceGeminiChatWindow } from '@/components/messages/VoiceGeminiChatWindow';

export const MessagesPage = () => {
  return <VoiceGeminiChatWindow autoSpeak={true} defaultLanguage="en-US" />;
};
```

**Done!** You now have full voice integration.

---

### Method 2: Add to Existing Component

```typescript
import { useSpeechToText } from '@/hooks/useSpeechToText';
import { useTextToSpeech } from '@/hooks/useTextToSpeech';

// 1. Add hooks
const { isListening, startListening, stopListening } = useSpeechToText({
  onTranscript: (text) => sendMessage(text),
});

const { speak } = useTextToSpeech();

// 2. Auto-speak responses
useEffect(() => {
  const lastMsg = messages[messages.length - 1];
  if (lastMsg?.role === 'assistant' && !lastMsg.isStreaming) {
    speak(lastMsg.content);
  }
}, [messages, speak]);

// 3. Add mic button
<button onClick={() => isListening ? stopListening() : startListening()}>
  {isListening ? 'â¹ï¸' : 'ğŸ¤'}
</button>
```

**Done!** Voice added to existing component.

---

## ğŸ¯ Common Use Cases

### 1. Voice Button Only
```typescript
const { isListening, startListening, stopListening } = useSpeechToText({
  onTranscript: (text) => handleMessage(text),
});

return (
  <button onClick={() => isListening ? stopListening() : startListening()}>
    ğŸ¤ {isListening ? 'Stop' : 'Speak'}
  </button>
);
```

### 2. Auto-Speak Responses
```typescript
const { speak } = useTextToSpeech({ lang: 'en-US' });

useEffect(() => {
  const lastMessage = messages[messages.length - 1];
  if (lastMessage?.role === 'assistant' && !lastMessage.isStreaming) {
    speak(lastMessage.content);
  }
}, [messages, speak]);
```

### 3. Multi-Language Support
```typescript
const [lang, setLang] = useState('en-US');
const { setLanguage: setSpeechLang } = useSpeechToText({ lang });
const { setLanguage: setSpeakLang } = useTextToSpeech({ lang });

const changeLang = (newLang: string) => {
  setLang(newLang);
  setSpeechLang(newLang);
  setSpeakLang(newLang);
};
```

### 4. Manual Speak Button
```typescript
const { speak, isSpeaking, cancel } = useTextToSpeech();

return messages.map(msg => (
  <div key={msg.id}>
    <p>{msg.content}</p>
    {msg.role === 'assistant' && (
      <button onClick={() => speak(msg.content)}>
        ğŸ”Š Speak
      </button>
    )}
  </div>
));
```

---

## ğŸ”§ Hook API Reference

### `useSpeechToText`

```typescript
const {
  isListening,        // boolean - Is currently recording
  transcript,         // string - Current transcript (interim + final)
  finalTranscript,    // string - Only final transcript
  interimTranscript,  // string - Only interim (partial) transcript
  isSupported,        // boolean - Is API supported
  error,              // string | null - Error message
  startListening,     // () => void - Start recording
  stopListening,      // () => void - Stop recording
  resetTranscript,    // () => void - Clear transcript
  setLanguage,        // (lang: string) => void - Change language
} = useSpeechToText({
  lang: 'en-US',                    // Language code
  interimResults: true,             // Show interim results
  continuous: false,                // Keep listening
  onTranscript: (text) => {},       // Callback when done
  onError: (error) => {},           // Error callback
});
```

### `useTextToSpeech`

```typescript
const {
  isSpeaking,         // boolean - Is currently speaking
  isSupported,        // boolean - Is API supported
  voices,             // SpeechSynthesisVoice[] - Available voices
  selectedVoice,      // SpeechSynthesisVoice | null - Current voice
  error,              // string | null - Error message
  speak,              // (text: string) => void - Speak text
  cancel,             // () => void - Stop speaking
  pause,              // () => void - Pause speech
  resume,             // () => void - Resume speech
  setVoice,           // (name: string) => void - Select voice
  setLanguage,        // (lang: string) => void - Change language
  setRate,            // (rate: number) => void - Speed (0.1-10)
  setPitch,           // (pitch: number) => void - Pitch (0-2)
  setVolume,          // (volume: number) => void - Volume (0-1)
} = useTextToSpeech({
  lang: 'en-US',                    // Language code
  rate: 1.0,                        // Speed
  pitch: 1.0,                       // Pitch
  volume: 1.0,                      // Volume
  voiceName: 'Google US English',  // Specific voice
  onStart: () => {},                // When starts
  onEnd: () => {},                  // When ends
  onError: (error) => {},           // Error callback
});
```

---

## ğŸŒ Language Codes

```
en-US  ğŸ‡ºğŸ‡¸  English (United States)
en-GB  ğŸ‡¬ğŸ‡§  English (United Kingdom)
bn-BD  ğŸ‡§ğŸ‡©  Bengali (Bangladesh)
hi-IN  ğŸ‡®ğŸ‡³  Hindi (India)
es-ES  ğŸ‡ªğŸ‡¸  Spanish (Spain)
fr-FR  ğŸ‡«ğŸ‡·  French (France)
de-DE  ğŸ‡©ğŸ‡ª  German (Germany)
ja-JP  ğŸ‡¯ğŸ‡µ  Japanese (Japan)
zh-CN  ğŸ‡¨ğŸ‡³  Chinese (Simplified)
ar-SA  ğŸ‡¸ğŸ‡¦  Arabic (Saudi Arabia)
```

---

## ğŸ› Troubleshooting

| Problem | Solution |
|---------|----------|
| Mic not working | Check browser permissions, use HTTPS |
| No speech recognized | Speak clearly, reduce background noise |
| Voice not speaking | Check volume, try different browser |
| Component not rendering | Verify imports, check Chakra UI setup |
| Browser not supported | Use Chrome, Edge, or Safari |

---

## ğŸ¨ UI States

### Voice Input States
```typescript
// Not listening
<Button>ğŸ¤ Speak</Button>

// Listening
<Button colorScheme="red">â¹ï¸ Stop</Button>
<Text>ğŸ¤ Listening... Speak now</Text>

// Processing
<Spinner /> <Text>Processing...</Text>

// Error
<Alert status="error">{error}</Alert>
```

### Voice Output States
```typescript
// Not speaking
<Button>ğŸ”Š Speak</Button>

// Speaking
<Button>ğŸ”‡ Stop</Button>
<Badge>ğŸ”Š Speaking</Badge>

// Auto-speak enabled
<IconButton icon={<FiVolume2 />} colorScheme="purple" />

// Auto-speak disabled
<IconButton icon={<FiVolumeX />} variant="outline" />
```

---

## âš™ï¸ Configuration Examples

### Conservative (Best Performance)
```typescript
useSpeechToText({
  lang: 'en-US',
  interimResults: false,    // No interim results
  continuous: false,
});

useTextToSpeech({
  rate: 1.2,                // Faster speech
  volume: 0.8,
});
```

### Optimal (Balanced)
```typescript
useSpeechToText({
  lang: 'en-US',
  interimResults: true,     // Show interim
  continuous: false,
});

useTextToSpeech({
  rate: 1.0,
  pitch: 1.0,
  volume: 1.0,
});
```

### Feature-Rich (All Features)
```typescript
useSpeechToText({
  lang: 'en-US',
  interimResults: true,
  continuous: true,         // Keep listening
  maxAlternatives: 3,       // Multiple alternatives
  onTranscript: handleTranscript,
  onError: handleError,
});

useTextToSpeech({
  rate: 0.9,                // Slightly slower
  pitch: 1.1,               // Slightly higher
  volume: 1.0,
  voiceName: 'Google UK English Female',
  onStart: () => console.log('Started'),
  onEnd: () => console.log('Ended'),
});
```

---

## ğŸ“Š Feature Support Matrix

| Feature | Chrome | Edge | Safari | Firefox |
|---------|--------|------|--------|---------|
| Voice Input | âœ… | âœ… | âœ… | âŒ |
| Voice Output | âœ… | âœ… | âœ… | âœ… |
| Interim Results | âœ… | âœ… | âš ï¸ | âŒ |
| Continuous Mode | âœ… | âœ… | âš ï¸ | âŒ |
| Multi-Language | âœ… | âœ… | âœ… | âŒ |

âœ… Full Support | âš ï¸ Partial Support | âŒ Not Supported

---

## ğŸš€ Next Steps

1. âœ… Read `VOICE_INTEGRATION_GUIDE.md` for complete documentation
2. âœ… Try `SimpleVoiceChat.tsx` example first
3. âœ… Use `VoiceGeminiChatWindow.tsx` for production
4. âœ… Review `VOICE_BEST_PRACTICES.md` for optimization
5. âœ… Check `VOICE_INTEGRATION_EXAMPLE.tsx` for integration steps

---

## ğŸ’¡ Pro Tips

1. **Always provide text fallback** - Not all browsers support voice
2. **Show clear visual feedback** - Users need to know what's happening
3. **Handle permissions gracefully** - Explain why you need mic access
4. **Test on real devices** - Desktop vs mobile behave differently
5. **Use HTTPS in production** - Required for voice features
6. **Reduce background noise** - Better recognition accuracy
7. **Keep messages concise** - Easier to speak and understand
8. **Add keyboard shortcuts** - Power users love them
9. **Monitor error rates** - Track voice feature adoption
10. **Provide instructions** - Most users are new to voice UI

---

## ğŸ“ Support

- **Documentation**: See `VOICE_INTEGRATION_GUIDE.md`
- **Examples**: Check `SimpleVoiceChat.tsx` and `VoiceGeminiChatWindow.tsx`
- **Best Practices**: Review `VOICE_BEST_PRACTICES.md`
- **Browser Issues**: Try Chrome, Edge, or Safari
- **Permissions**: Check browser settings â†’ Privacy â†’ Microphone

---

**Happy Voice Chatting! ğŸ¤ğŸ¤–**
